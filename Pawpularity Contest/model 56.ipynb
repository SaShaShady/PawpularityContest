{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Pretrained Image Model to Predict Pet Popularity","metadata":{}},{"cell_type":"markdown","source":"Pretrained **EfficientNetB0 model from Keras applications** is used to extract features from images resized to 224 x 224. Popularity score is estimated based solely on images. Tabular data is ignored. Since image quality affects the target value only horizontal flip is used for data augmentation.","metadata":{}},{"cell_type":"code","source":"import os\nimport random\n\nimport pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-14T01:42:13.341479Z","iopub.execute_input":"2021-12-14T01:42:13.341752Z","iopub.status.idle":"2021-12-14T01:42:13.346729Z","shell.execute_reply.started":"2021-12-14T01:42:13.341723Z","shell.execute_reply":"2021-12-14T01:42:13.346009Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# Tabular data file paths\nTRAIN_DATA_PATH = '../input/petfinder-pawpularity-score/train.csv'\nTEST_DATA_PATH = '../input/petfinder-pawpularity-score/test.csv'\n\n# Image data directories\nTRAIN_DIRECTORY = '../input/petfinder-pawpularity-score/train'\nTEST_DIRECTORY = '../input/petfinder-pawpularity-score/test'","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.377787Z","iopub.execute_input":"2021-12-14T01:42:13.378623Z","iopub.status.idle":"2021-12-14T01:42:13.383378Z","shell.execute_reply.started":"2021-12-14T01:42:13.378585Z","shell.execute_reply":"2021-12-14T01:42:13.382465Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"# Parameters for processing tabular data\nTARGET_NAME = 'Pawpularity'\nVAL_SIZE = 0.15\nSEED = 5","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.384961Z","iopub.execute_input":"2021-12-14T01:42:13.385919Z","iopub.status.idle":"2021-12-14T01:42:13.392779Z","shell.execute_reply.started":"2021-12-14T01:42:13.385884Z","shell.execute_reply":"2021-12-14T01:42:13.391971Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# TensorFlow settings and training parameters\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 224\nBATCH_SIZE = 64\nDROPOUT_RATE = 0.2\nLEARNING_RATE = 1e-3\nDECAY_STEPS = 100\nDECAY_RATE = 0.96\nEPOCHS = 500\nPATIENCE = 5","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.393980Z","iopub.execute_input":"2021-12-14T01:42:13.394311Z","iopub.status.idle":"2021-12-14T01:42:13.403170Z","shell.execute_reply.started":"2021-12-14T01:42:13.394276Z","shell.execute_reply":"2021-12-14T01:42:13.402480Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"# Pretrained image classification model EfficientNetB0\n# from tf.keras.applications with global average pooling as a final layer.\n# In this notebook the model is loaded from a public dataset on Kaggle\n# at https://www.kaggle.com/ekaterinadranitsyna/keras-applications-models\nIMG_MODEL = '../input/keras-pretrained-models/MobileNet_Top_None.h5'","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.404814Z","iopub.execute_input":"2021-12-14T01:42:13.405314Z","iopub.status.idle":"2021-12-14T01:42:13.412477Z","shell.execute_reply.started":"2021-12-14T01:42:13.405278Z","shell.execute_reply":"2021-12-14T01:42:13.411476Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"markdown","source":"## Functions","metadata":{}},{"cell_type":"code","source":"def set_seed(seed=42):\n    \"\"\"Utility function to use for reproducibility.\n    :param seed: Random seed\n    :return: None\n    \"\"\"\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n\n\ndef set_display():\n    \"\"\"Function sets display options for charts and pd.DataFrames.\n    \"\"\"\n    # Plots display settings\n    plt.style.use('fivethirtyeight')\n    plt.rcParams['figure.figsize'] = 12, 8\n    plt.rcParams.update({'font.size': 14})\n    # DataFrame display settings\n    pd.set_option('display.max_columns', None)\n    pd.set_option('display.max_rows', None)\n    pd.options.display.float_format = '{:.4f}'.format\n\n\ndef id_to_path(img_id: str, dir: str):\n    \"\"\"Function returns a path to an image file.\n    :param img_id: Image Id\n    :param dir: Path to the directory with images\n    :return: Image file path\n    \"\"\"\n    return os.path.join(dir, f'{img_id}.jpg')\n\n\n@tf.function\ndef get_image(path: str) -> tf.Tensor:\n    \"\"\"Function loads image from a file and preprocesses it.\n    :param path: Path to image file\n    :return: Tensor with preprocessed image\n    \"\"\"\n    image = tf.image.decode_jpeg(tf.io.read_file(path), channels=3)\n    image = tf.cast(tf.image.resize_with_pad(image, IMG_SIZE, IMG_SIZE), dtype=tf.int32)\n    return tf.keras.applications.efficientnet.preprocess_input(image)\n\n\n@tf.function\ndef process_dataset(path: str, label: int) -> tuple:\n    \"\"\"Function returns preprocessed image and label.\n    :param path: Path to image file\n    :param label: Class label\n    :return: tf.Tensor with preprocessed image, numeric label\n    \"\"\"\n    return get_image(path), label\n\n\n@tf.function\ndef get_dataset(x, y=None) -> tf.data.Dataset:\n    \"\"\"Function creates batched optimized dataset for the model\n    out of an array of file paths and (optionally) class labels.\n    :param x: Input data for the model (array of file paths)\n    :param y: Target values for the model (array of class indexes)\n    :return TensorFlow Dataset object\n    \"\"\"\n    if y is not None:\n        ds = tf.data.Dataset.from_tensor_slices((x, y))\n        return ds.map(process_dataset, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n    else:\n        ds = tf.data.Dataset.from_tensor_slices(x)\n        return ds.map(get_image, num_parallel_calls=AUTOTUNE) \\\n            .batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n\n\ndef plot_history(hist):\n    \"\"\"Function plots a chart with training and validation metrics.\n    :param hist: Tensorflow history object from model.fit()\n    \"\"\"\n    # Losses and metrics\n    loss = hist.history['loss']\n    val_loss = hist.history['val_loss']\n    rmse = hist.history['root_mean_squared_error']\n    val_rmse = hist.history['val_root_mean_squared_error']\n\n    # Epochs to plot along x axis\n    x_axis = range(1, len(loss) + 1)\n\n    fig, (ax1, ax2) = plt.subplots(nrows=2, ncols=1, sharex=True)\n\n    ax1.plot(x_axis, loss, 'bo', label='Training')\n    ax1.plot(x_axis, val_loss, 'ro', label='Validation')\n    ax1.set_title('MSE Loss')\n    ax1.legend()\n\n    ax2.plot(x_axis, rmse, 'bo', label='Training')\n    ax2.plot(x_axis, val_rmse, 'ro', label='Validation')\n    ax2.set_title('Root Mean Squared Error')\n    ax2.set_xlabel('Epochs')\n    ax2.legend()\n\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.414264Z","iopub.execute_input":"2021-12-14T01:42:13.414518Z","iopub.status.idle":"2021-12-14T01:42:13.438219Z","shell.execute_reply.started":"2021-12-14T01:42:13.414485Z","shell.execute_reply":"2021-12-14T01:42:13.437518Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## Data Processing","metadata":{}},{"cell_type":"code","source":"set_seed(SEED)\nset_display()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.440112Z","iopub.execute_input":"2021-12-14T01:42:13.440450Z","iopub.status.idle":"2021-12-14T01:42:13.452623Z","shell.execute_reply.started":"2021-12-14T01:42:13.440418Z","shell.execute_reply":"2021-12-14T01:42:13.451954Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"# Train data set\ndata_train = pd.read_csv(TRAIN_DATA_PATH)\nprint(f'Train data shape: {data_train.shape}')\ndata_train.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.455598Z","iopub.execute_input":"2021-12-14T01:42:13.456607Z","iopub.status.idle":"2021-12-14T01:42:13.491318Z","shell.execute_reply.started":"2021-12-14T01:42:13.456571Z","shell.execute_reply":"2021-12-14T01:42:13.490610Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# Test data set\ndata_test = pd.read_csv(TEST_DATA_PATH)\nprint(f'Test data shape: {data_test.shape}')\ndata_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.492576Z","iopub.execute_input":"2021-12-14T01:42:13.493027Z","iopub.status.idle":"2021-12-14T01:42:13.512906Z","shell.execute_reply.started":"2021-12-14T01:42:13.492992Z","shell.execute_reply":"2021-12-14T01:42:13.512089Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"# Reconstruct the paths to train and test images.\ndata_train['path'] = data_train['Id'].apply(\n    lambda x: id_to_path(x, TRAIN_DIRECTORY))\ndata_test['path'] = data_test['Id'].apply(\n    lambda x: id_to_path(x, TEST_DIRECTORY))\n\n# Keep a portion of the labeled data for validation.\ntrain_subset, valid_subset = train_test_split(\n    data_train[['path', TARGET_NAME]],\n    test_size=VAL_SIZE, shuffle=True, random_state=SEED\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.514057Z","iopub.execute_input":"2021-12-14T01:42:13.514538Z","iopub.status.idle":"2021-12-14T01:42:13.548746Z","shell.execute_reply.started":"2021-12-14T01:42:13.514500Z","shell.execute_reply":"2021-12-14T01:42:13.548126Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"# Create TensorFlow datasets\ntrain_ds = get_dataset(x=train_subset['path'], y=train_subset[TARGET_NAME])\nvalid_ds = get_dataset(x=valid_subset['path'], y=valid_subset[TARGET_NAME])\ntest_ds = get_dataset(x=data_test['path'])","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.549868Z","iopub.execute_input":"2021-12-14T01:42:13.550542Z","iopub.status.idle":"2021-12-14T01:42:13.893761Z","shell.execute_reply.started":"2021-12-14T01:42:13.550503Z","shell.execute_reply":"2021-12-14T01:42:13.892895Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"# Pretrained image classification model\nfeature_model = tf.keras.models.load_model(IMG_MODEL)\n\n# Freeze weights in the original model\nfeature_model.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:13.895245Z","iopub.execute_input":"2021-12-14T01:42:13.895589Z","iopub.status.idle":"2021-12-14T01:42:15.002968Z","shell.execute_reply.started":"2021-12-14T01:42:13.895549Z","shell.execute_reply":"2021-12-14T01:42:15.002180Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"# This model takes in 224 x 224 images, applies random horizontal flip\n# (only in the train mode), passes image arrays through pretrained\n# feature extraction model and applies batch normalization, dropout\n# and activations to get the target score.\nimage_model = tf.keras.models.Sequential(\n    [\n        tf.keras.layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3)),\n        tf.keras.layers.experimental.preprocessing.RandomFlip(mode='horizontal'),\n        feature_model,\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(DROPOUT_RATE, name='top_dropout'),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.Dense(1, name='score')\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.006385Z","iopub.execute_input":"2021-12-14T01:42:15.006603Z","iopub.status.idle":"2021-12-14T01:42:15.233693Z","shell.execute_reply.started":"2021-12-14T01:42:15.006578Z","shell.execute_reply":"2021-12-14T01:42:15.232996Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"# To gradually decrease learning rate\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate=LEARNING_RATE,\n    decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE,\n    staircase=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.234986Z","iopub.execute_input":"2021-12-14T01:42:15.235246Z","iopub.status.idle":"2021-12-14T01:42:15.238786Z","shell.execute_reply.started":"2021-12-14T01:42:15.235211Z","shell.execute_reply":"2021-12-14T01:42:15.238146Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"# Compile the model\nimage_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n                    loss=tf.keras.losses.MeanSquaredError(),\n                    metrics=[tf.keras.metrics.RootMeanSquaredError()])","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.240126Z","iopub.execute_input":"2021-12-14T01:42:15.240613Z","iopub.status.idle":"2021-12-14T01:42:15.264617Z","shell.execute_reply.started":"2021-12-14T01:42:15.240532Z","shell.execute_reply":"2021-12-14T01:42:15.264026Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"image_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.265683Z","iopub.execute_input":"2021-12-14T01:42:15.265924Z","iopub.status.idle":"2021-12-14T01:42:15.281344Z","shell.execute_reply.started":"2021-12-14T01:42:15.265890Z","shell.execute_reply":"2021-12-14T01:42:15.280659Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# To monitor validation loss and stop the training.\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', patience=PATIENCE, restore_best_weights=True)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.282632Z","iopub.execute_input":"2021-12-14T01:42:15.282950Z","iopub.status.idle":"2021-12-14T01:42:15.287068Z","shell.execute_reply.started":"2021-12-14T01:42:15.282914Z","shell.execute_reply":"2021-12-14T01:42:15.286260Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"history = image_model.fit(train_ds, validation_data=valid_ds,\n                          epochs=EPOCHS, callbacks=[early_stop],\n                          use_multiprocessing=True, workers=-1)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:42:15.288570Z","iopub.execute_input":"2021-12-14T01:42:15.288904Z","iopub.status.idle":"2021-12-14T01:46:10.645498Z","shell.execute_reply.started":"2021-12-14T01:42:15.288804Z","shell.execute_reply":"2021-12-14T01:46:10.644752Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:46:10.646606Z","iopub.execute_input":"2021-12-14T01:46:10.646859Z","iopub.status.idle":"2021-12-14T01:46:11.049825Z","shell.execute_reply.started":"2021-12-14T01:46:10.646812Z","shell.execute_reply":"2021-12-14T01:46:11.049040Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"# Predict popularity score for the test\ndata_test[TARGET_NAME] = image_model.predict(\n    test_ds, use_multiprocessing=True, workers=os.cpu_count())","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:46:11.051157Z","iopub.execute_input":"2021-12-14T01:46:11.051416Z","iopub.status.idle":"2021-12-14T01:46:11.702681Z","shell.execute_reply.started":"2021-12-14T01:46:11.051380Z","shell.execute_reply":"2021-12-14T01:46:11.701743Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"data_test[['Id', TARGET_NAME]].to_csv('submission.csv', index=False)\ndata_test[['Id', TARGET_NAME]].head()","metadata":{"execution":{"iopub.status.busy":"2021-12-14T01:46:11.704479Z","iopub.execute_input":"2021-12-14T01:46:11.704729Z","iopub.status.idle":"2021-12-14T01:46:11.723925Z","shell.execute_reply.started":"2021-12-14T01:46:11.704692Z","shell.execute_reply":"2021-12-14T01:46:11.723237Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}